ü§ñ **Exam Guide:** AI Practitioner
**Domain 5: Security, Compliance, and Governance for AI Solutions**
üìò _Task Statement 5.1_

## üéØ Objectives
**Domain 5** focuses on protecting data, models, and AI-powered applications in the real world. You‚Äôre expected to understand the main AWS security building blocks _(IAM, encryption, PrivateLink, Macie, shared responsibility)_, plus AI-specific risks like prompt injection and data leakage, and how documentation _(lineage, catalogs, model cards) _supports governance.

---

### 1) AWS Services And Features Used To Secure AI Systems

#### 1.1 **IAM Roles, Policies, and Permissions**
Control *who/what* can access AI services, data, and model endpoints.
**Best Practice:** *least privilege* aka grant only what‚Äôs needed and use roles instead of long-lived credentials.

#### 1.2 **Encryption**
Protect sensitive data:
**at rest:** stored in S3, databases, logs
**in transit:** moving between services/users
_Know the concept and why it matters for privacy and compliance._

#### 1.3 **Amazon Macie**
Helps discover and protect sensitive data _(PII)_ stored in Amazon S3.
_Amazon Macie is Useful for reducing accidental exposure of regulated data in training sets, logs, or retrieval corpora._

#### 1.4 **AWS PrivateLink**
Provides private connectivity to AWS services without traversing the public internet.
AWS PrivateLink is useful when AI workloads must remain within private networks for security/compliance reasons.

#### 1.5 **AWS Shared Responsibility Model**
AWS secures the underlying cloud infrastructure and customers secure what they build/configure such as data, IAM, apps, network settings.
_Know what is AWS‚Äôs responsibility vs the customer‚Äôs responsibility in AI solutions._

---

### 2) Source Citation And Documenting Data Origins 
#### Governance Foundations

#### 2.1 **Source Citation**
Attaching references to where an answer came from especially in RAG systems.
**Benefits:** improves trust, auditability, and helps users verify correctness.

#### 2.2 **Documenting Data Origins**
**_1_** **Data lineage**: tracking where data came from and how it changed over time.
**_2_** **Data cataloging**: organizing datasets with metadata such as owner, sensitivity, schema, allowed use.
**_3_** **SageMaker Model Cards:** Document model purpose, training/eval context, limitations, and considerations‚Äîhelpful for governance and audits.

---

### 3) Best Practices For Secure Data Engineering

#### 3.1 **Assess Data Quality**
Prevent _‚Äúgarbage in, garbage out‚Äù_ and reduce risk of training on corrupted or biased data.
_Assessing Data Quality includes checking label quality, duplicates, missing values, outliers, and integrity._

#### 3.2 **Privacy-Enhancing Technologies (PETs)**
Techniques that reduce privacy risk while enabling analytics/ML.
**Examples:** _anonymization/pseudonymization, tokenization, differential privacy._

#### 3.3 **Data Access Control**
Limit who can read/write sensitive datasets, features, prompts, and logs.
_Use IAM + resource policies + least privilege and segment access by environment (dev/test/prod, etc)._

#### 3.4 **Data Integrity**
Ensure data is not altered maliciously or accidentally.
_Data Integrity includes versioning, checksums/hashes, controlled pipelines, audit logs._

---

### 4) Security And Privacy Considerations For AI Systems

#### 4.1 **Application Security**
**Secure the app layer:**_ authentication, authorization, input validation, secure APIs, rate limiting._

#### 4.2 **Threat Detection**
Detect abnormal access patterns, data exfiltration attempts, suspicious usage spikes, or policy violations.

#### 4.3 **Vulnerability Management**
Patch dependencies, scan containers, and manage CVEs in runtime environments and libraries.

#### 4.4 **Infrastructure Protection**
Network segmentation, private connectivity where needed, least privilege IAM, secure endpoints.

#### 4.5 **Prompt Injection**
Malicious input tries to override system instructions or exfiltrate data which is especially risky with RAG.
**Mitigations:** 
**_1_** input filtering, 
**_2_** strict tool permissions, 
**_3_** grounding rules, 
**_4_** guardrails, 
**_5_** isolating sensitive context, 
**_6_** and not trusting retrieved/user text as ‚Äúinstructions.‚Äù

#### 4.6 **Encryption At Rest And In Transit**
Protects data used for:
  **_1_** training/fine-tuning datasets
  **_2_** embedding/vector stores
  **_3_** prompts and conversation history
  **_4_** logs and monitoring outputs

---

### üí° **Quick Questions**

**1** What AWS feature is used to enforce least-privilege access to AI resources?
**2** What does **Amazon Macie** help you detect in S3?
**3** Why is **source citation** valuable in a RAG-based assistant?
**4** Name two secure data engineering practices that reduce privacy or integrity risk.
**5** What is **prompt injection**, and why is it a security concern for GenAI apps?


## Additional Resources
1. [Shared Responsibility Model](https://aws.amazon.com/compliance/shared-responsibility-model/)
2. [Data Protection in Amazon SageMaker AI](https://docs.aws.amazon.com/sagemaker/latest/dg/data-protection.html)
3. [What is Amazon Macie?](https://docs.aws.amazon.com/macie/latest/user/what-is-macie.html)
4. [AWS PrivateLink for Amazon S3](https://docs.aws.amazon.com/AmazonS3/latest/userguide/privatelink-interface-endpoints.html)
5. [Amazon Sagemaker Model Cards](https://docs.aws.amazon.com/sagemaker/latest/dg/model-cards.html)
6. [Amazon SageMaker ML Lineage Tracking](https://docs.aws.amazon.com/sagemaker/latest/dg/lineage-tracking.html)
7. [AWS Clean Rooms - data collaboration service](https://aws.amazon.com/clean-rooms/)
8. [Securing generative AI: An introduction to the Generative AI Security Scoping Matrix](https://aws.amazon.com/blogs/security/securing-generative-ai-an-introduction-to-the-generative-ai-security-scoping-matrix/)
9. [Amazon Bedrock Guardrails](https://aws.amazon.com/bedrock/guardrails/)
10. [Implementing least privilege access for Amazon Bedrock](https://aws.amazon.com/blogs/security/implementing-least-privilege-access-for-amazon-bedrock/) 
11. [Securing AI](https://aws.amazon.com/ai/security/)



### ‚úÖ _Answers to Quick Questions_
**1** IAM roles and policies or _permissions_.

**2** Sensitive data such as PII and other regulated/sensitive content in S3.

**3** It improves trust and auditability by showing where answers came from so users can verify them and you can trace issues.

**4** Data access control through least privilege and privacy-enhancing techniques such  anonymization or tokenization.
**also valid:** _data quality checks, integrity controls like versioning/audit logs._

**5** Malicious prompts that try to override instructions or extract secrets, it‚Äôs dangerous because untrusted user/retrieved text can cause unsafe actions, data leakage, or policy violations.

# The Original

**Blog:** [Ntombizakhona Mabaso](https://dev.to/ntombizakhona)
<br>
**Article Link:** [Explain Methods To Secure AI Systems](https://dev.to/aws-builders/explain-methods-to-secure-ai-systems-iei)
<br>
Originally Published by [Ntombizakhona Mabaso](https://dev.to/ntombizakhona)
<br>
**25 January 2026**
